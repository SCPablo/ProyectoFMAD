---
title: "Proyecto FMAD"
subtitle: ICAI. Máster en Big Data. Fundamentos Matemáticos del Análisis de Datos
  (FMAD).
date: 'Curso 2021-22. Última actualización: `r format(Sys.time(), "%Y-%m-%d")`'
linestretch: "1.25"
header-includes:
  \usepackage[spanish]{babel}
output:
  pdf_document: default
  html_document: default
---

\begin{center}
\includegraphics{logoicai.png}
\end{center}

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

\newpage
\tableofcontents
\newpage


# 1. Introducción

Lo primero que haremos será cargar las diferentes librerias que usaremos para nuestro proyecto. Entre ellas encontraremos librerias públicas como tidyverse y algunas privadas como MLTools:


```{r, warning=FALSE,message=FALSE}
library(tidyverse)
library(lubridate)
library(caret)
library(grid)
library(corrplot)
library(gridExtra)
library(ROCR)
library(MLTools)
library(GGally)
library(rpart)
library(rpart.plot)
library(partykit)
library(kernlab)
library(NeuralNetTools) 
library(NeuralSens)
library(nnet)
library(ROSE)
library(randomForest)
```


A continuación leeremos los datos con los que trabajaremos:

```{r}
datos <- read.csv("marketing_campaign.csv", header = TRUE, sep = "")
```

\newpage

# 2. Definición de las variables

Antes de comenzar con el preprocesamiento de los datos lo que haremos será listar las variables y lo que representa cada una de ella:

- **ID**: El ID del cliente.

- **Year_Birth:** Indica el año de nacimiento del cliente.

- **Education:** Indica el nivel de educación del cliente.

- **Marital_Status:** Indica el estado civil del cliente.

- **Income:** Presenta el ingreso familiar anual del cliente.

- **Kidhome:** Indica el número de niños pequeños en casa del cliente.

- **Teenhome:** Indica el número de adolescentes en el hogar del cliente.

- **Dt_Customer:** Muestra la fecha de inscripción del cliente en la empresa.

- **Recency:** El número de días desde la última compra.

- **MntWines:** El gasto en productos vitivinícolas en los últimos 2 años.

- **MntGoldProds:** El gasto en productos premium en los últimos 2 años.

- **NumDealsPurchases:** El número de compras con uso de descuento.

- **NumWebPurchases:** El número de compras a través de la web.

- **NumCatalogPurchases:** El número de compras usando catalogo.

- **NumWebVisitsMonth:** El número de visitas por mes a la web.

- **AcceptedCmp1:** 1 si el cliente acepta la oferta en la 1ra campaña, 0 si no lo acepta.

- **AcceptedCmp2:** 1 si el cliente acepta la oferta en la 2nd campaña, 0 si no lo acepta.

- **Complain:** 1 si el cliente se ha quejado en los dos últimos años.

- **Z_CostContact:** El coste de contactar con cliente.

- **Z_Revenue:** Los ingresos/beneficios después de que el cliente acepte la campaña.

- **Response:** 1 si el cliente acepta la oferta en la última campaña y 0 si no la acepta.



\newpage

# 3. Preprocesamiento

## 3.1. Resumen de datos 

Lo primero que haremos será ver como esta estructurado nuestro dataset. Para ello veremos que tamaño tiene, tanto filas como columnas. A su vez también veremos con que tipo de datos estamos trabajando.

```{r}
cat(cat(cat(cat("El conjunto de datos tiene", nrow(datos)), "filas y"), 
        ncol(datos)), "columnas")
str(datos)
```

Una vez visto el tipo de variables con las que trabajamos es facilmente observable la necesidad de realizar algunas modificaciones en algunas de ellas.

Ahora veremos un resumen de las variables que tenemos:

```{r}
summary(datos)
```

Observamos que existen numerosos valores nulos en nuestras variables. En el punto siguiente veremos que hacer con estos casos.



## 3.2. Análisis de las variables

Lo primero que haremos será eliminar las filas que contienen datos nulos. Esto podemos hacerlo ya que disponemos de una muestra muy grande y eliminar los valores nulos no afectará para nuestro trabajo.

```{r}
datos <- na.omit(datos)
```


Además, también observamos que hay algunos datos erróneos por lo que por el mismo motivo que antes procederemos a eliminarlos.

```{r}
datos <- datos %>%
  filter(ID != 0 & ID != 1 & Education != "2n" & Income > 10 & Income != "2")
```


Además el conjunto de datos tiene muchas columnas las cuales no nos resultan interesantes, por ello vamos a eliminar algunas de ellas: "NumDealsPurchases", "Receny", "AcceptedCmp1", "AcceptedCmp2", "AcceptedCmp3", "AcceptedCmp4" y "AcceptedCmp5", "Z_CostContact" y "Z_Revenue".

```{r}
datos <- datos %>%
  select(-c(AcceptedCmp3:AcceptedCmp2), -NumDealsPurchases, -Recency, 
         -Z_CostContact, -Z_Revenue)
```


También como vimos cuando hicimos la visión general de las variables y su tipo, nos dimos cuenta de que algunas de ellas estaban mal tipadas. Por ello cambiaremos el tipado de algunas columnas.

```{r}
datos$Teenhome <- as.numeric(datos$Teenhome)
datos$Income <- as.numeric(datos$Income)
datos$Complain <- as.factor(datos$Complain)
datos$Education <- as.factor(datos$Education)
datos$Response <- as.factor(datos$Response)
```


A su vez hemos observado que algunas columnas podrían tener un formato más útil o sencillo, como es el caso del año de nacimiento, donde es mas cómodo trabajar con edades. 
Por tanto, para un mejor procesamiento y una mayor útilidad realizaremos un mutate para generar una nueva columna formada por la edad de los clientes. A su vez eliminaremos la columna de año de nacimiento.

```{r}
datos <- datos %>%
  mutate(edad = 2021 - Year_Birth) %>%
  select(-Year_Birth) 
```

También nos pareció interesante en vez de distinguir entre número de hijos los cuales son pequeños o son adolescentes, tomarlos como una única variable que nos indique el número de hijos que hay en cada hogar. Para ello sumaremos el total de niños de cada cliente agrupando las columnas Kidhome y Teenhome.

```{r}
datos <- datos %>%
  mutate(totalHijos = Kidhome + Teenhome) %>%
  select(-Kidhome, -Teenhome)
```


Como en el caso de los hijos para las compras haremos algo similar, donde cogeremos las columnas "NumWebPurchases", "NumCatalogPurchases" y "NumStorePurchases" que indican el número de compras hechas en cada sitio, en tiendas, por catalogo y por la web y las sumaremos todas en una única columna que indique el total de compras que ha realizado el cliente.

```{r}
datos <- datos %>%
  rowwise(ID) %>%
  mutate(suma_compras = sum(c(NumWebPurchases, NumCatalogPurchases, 
                              NumStorePurchases))) %>%
  select(-c(NumWebPurchases, NumCatalogPurchases, NumStorePurchases))
```



A su vez, para el gasto en los diferentes tipos de producto sumaremos las columans: "MntWines", "MntFruits", "MntMeatProducts",  "MntFishProducts",  "MntSweetProducts",  "MntGoldProds" lo cual nos indicara cuánto dinero se ha gastado un cliente en total.

```{r}
datos <- datos %>%
  rowwise(ID) %>%
  mutate(Dinero_Gastado = sum(c(MntWines, MntFruits, MntMeatProducts, MntFishProducts, 
                                MntSweetProducts, MntGoldProds)))
```



También existe una variable que nos indica el estado civil del cliente, al existir numerosas situaciones nosotros agruparemos el estado civil de cada cliente y lo simplificamos para ver si vive solo o en pareja. Ya que esto nos podrá resultar interesante para análisis posteriores.

```{r}
datos <- datos %>%
  mutate(Marital_Status = factor(Marital_Status== "Single" | Marital_Status== "Divorced", 
                          levels = c(TRUE, FALSE), labels = c('Single','Not single')))
```


Por último cambiaremos la columna Dt_Customer y estableceremos 3 grupos que representan la longevidad del cliente en la empresa.

```{r}
datos$Dt_Customer = as.Date(datos$Dt_Customer, "%d-%m-%Y")
fechaMinima = min(datos$Dt_Customer)
datos$Dt_Customer <-  factor(cut_number(as.duration(datos$Dt_Customer-fechaMinima), 
                      n = 3), labels = c("Nuevo", "Con Experiencia", "Muy Antiguo"), 
                      ordered = TRUE)
```




## 3.3. Visualización de los datos

En este apartado lo que realizaremos será un análisis mediante gráficas de las variables según su tipo, viendo si siguen una distribución normal y si presentarían outliers entre otros factores.

Comenzaremos con las variables continuas, que son las siguientes:

```{r, warning=FALSE, message=FALSE}
h1 <- ggplot(datos)+
  geom_histogram(aes(x = Income), color = "black", alpha = 0.35)
h2 <- ggplot(datos)+
  geom_histogram(aes(x = MntWines ), color = "black", alpha = 0.35)
h3 <- ggplot(datos)+
  geom_histogram(aes(x = MntFruits ), color = "black", alpha = 0.35)
h4 <- ggplot(datos)+
  geom_histogram(aes(x = MntMeatProducts ), color = "black", alpha = 0.35)
h5 <- ggplot(datos)+
  geom_histogram(aes(x = MntFishProducts ), color = "black", alpha = 0.35)
h6 <- ggplot(datos)+
  geom_histogram(aes(x = MntSweetProducts ), color = "black", alpha = 0.35)
h7 <- ggplot(datos) +
  geom_histogram(aes(x = MntGoldProds ), color = "black", alpha = 0.35)
h8 <- ggplot(datos) +
  geom_histogram(aes(x = Dinero_Gastado), color = "black", alpha = 0.35)
h9 <- ggplot(datos)+
  geom_histogram(aes(x = suma_compras ), color = "black", alpha = 0.35)
h10 <- ggplot(datos)+
  geom_histogram(aes(x = NumWebVisitsMonth ), color = "black", alpha = 0.35)
h12 <- ggplot(datos)+
  geom_histogram(aes(x = edad ), color = "black", alpha = 0.35)
grid.arrange(h1,h2,h3,h4,h5,h6,h7,h8,h9,h10,h12)
```

Podemos observar en los histogramas que ninguna de las variables sigue una distribución normal. El patrón más común es un gran número de datos con valores pequeños y muchos menos datos a medida que el valor de la variable del eje x aumenta. Por este motivo, aunque no los mostremos, podemos deducir que existen outliers en casi todas las variables. Un caso bastante claro de outlier se puede ver en la variable edad donde vemos que el eje x llega a 125 lo cual nos indica que debe existir alguna observación con valor por encima de 115 y menor de 125.


En cuanto a las variables discretas tenemos lo siguiente:

```{r}
hb1 <- ggplot(datos)+
  geom_bar(aes(x = Education), color = "black", alpha = 0.35)
hb2 <- ggplot(datos) + 
  geom_bar(aes(x = Marital_Status), color = "black", alpha = 0.35)
hb3 <- ggplot(datos) + 
  geom_bar(aes(x = Dt_Customer), color = "black", alpha = 0.35)
hb4 <- ggplot(datos) + 
  geom_bar(aes(x = Complain), color = "black", alpha = 0.35)

grid.arrange(hb1, hb2, hb3, hb4, ncol = 2)
```

En estas variables podemos observar diferentes patrones. Si miramos la educación de los clientes nos damos cuenta que hay mucha diferencia entre el número de clientes que tienen una educación básica y el resto de tipos, sobre todo los clientes graduados. De la misma forma vemos que hay más del doble de clientes not single que single. Por otro lado tenemos que la longividad de los clientes es uniforme. En cuanto a la variable complain observamos que unicamente un porcentaje muy pequeño de los clientes se han quejado durante los dos últimos años.


\newpage

# 3. Análisis Predictivo y Analítica Avanzada

## 3.1. Preprocesamiento

En esta sección nuestro objetivo es usar técnicas de Machine Learning para predecir tendencias y comportamientos sobre diferentes variables que nos puedan resultar interesantes. 

Para ello crearemos un nuevo conjunto de datos sacados de los datos que hemos refinado en la parte anterior. A su vez en un primer momento hemos analizado la relación entre tener hijos y los gastos en compras de cada tipo.

```{r}
datos_ML<-datos %>%
  mutate(sonPadres = factor(totalHijos>0, levels = c(FALSE, TRUE), labels = c(0,1)))
borrar <- c("MntWines", "MntFruits", "MntMeatProducts",  "MntFishProducts", "MntSweetProducts", "MntGoldProds","Dinero_Gastado", "sonPadres", "totalHijos")
datos_ML <- datos_ML[(names(datos_ML) %in% borrar)]
head(datos_ML) 
```

Lo primero que haremos sera ver como se relacionan las diferentes variables con las variables de output, empezando por si tienen hijos.

```{r}
g1 <-ggplot(datos_ML) + 
  geom_boxplot(aes(x = sonPadres, y = MntWines))
g2<-ggplot(datos_ML) + 
  geom_boxplot(aes(x = sonPadres, y = MntFruits))
g3<-ggplot(datos_ML) + 
  geom_boxplot(aes(x = sonPadres, y = MntMeatProducts))
g4<-ggplot(datos_ML) + 
  geom_boxplot(aes(x = sonPadres, y = MntFishProducts))
g5<-ggplot(datos_ML) + 
  geom_boxplot(aes(x = sonPadres, y = MntSweetProducts))
g6<-ggplot(datos_ML) + 
  geom_boxplot(aes(x = sonPadres, y = MntGoldProds))
g7<-ggplot(datos_ML) + 
  geom_boxplot(aes(x = sonPadres, y = Dinero_Gastado))
gridExtra::grid.arrange(g1,g2,g3,g4, g5, g6, g7)
```
Vemos que si los clientes tienen hijos, el gasto en todos los productos se reduce. Pero ya que hemos llegado hasta aquí, queremos además observar la relación entre el número de hijos y dichos gastos. Veamos los siguientes gráficos.

```{r}
gb1 <-ggplot(datos_ML) + 
  geom_boxplot(aes(x = factor(totalHijos), y = MntWines))
gb2<-ggplot(datos_ML) + 
  geom_boxplot(aes(x = factor(totalHijos), y = MntFruits))
gb3<-ggplot(datos_ML) + 
  geom_boxplot(aes(x = factor(totalHijos), y = MntMeatProducts))
gb4<-ggplot(datos_ML) + 
  geom_boxplot(aes(x = factor(totalHijos), y = MntFishProducts))
gb5<-ggplot(datos_ML) + 
  geom_boxplot(aes(x = factor(totalHijos), y = MntSweetProducts))
gb6<-ggplot(datos_ML) + 
  geom_boxplot(aes(x = factor(totalHijos), y = MntGoldProds))
gb7<-ggplot(datos_ML) + 
  geom_boxplot(aes(x = factor(totalHijos), y = Dinero_Gastado))
gridExtra::grid.arrange(gb1,gb2,gb3,gb4, gb5, gb6, gb7)
```
Siguiendo con la relación anterior, observamos que a más hijos menor es el gasto en todos los productos.


Veamos la relación entre la edad y los gastos de compras. Primero vamos a ver la distribución de la edad.

```{r}
ggplot(datos) +
  geom_histogram(aes(x = edad, y =stat(density)), bins = 15, fill = "darkgreen", 
                 color = "black") +
  geom_density(aes(x = edad), color="red", size=1.5)
```
Como hemos comentado anteriormente existe un valor atípico dentro de nuestra variable, por lo que al unicamente ser uno lo eliminaremos (ya que no afectará a la información) y volvemos a examinar los datos.

```{r}
datos <- datos %>%
  filter(edad < 100)
ggplot(datos) +
  geom_histogram(aes(x = edad, y =stat(density)), bins = 15, fill = "darkgreen",
                 color ='black') +
  geom_density(aes(x = edad), color="red", size=1.5)
```


Observamos que nuestros datos ya tienen una forma que es plausible, por lo que podemos iniciar el análisis de los datos.

```{r}
g1 <-ggplot(datos) + 
  geom_jitter(aes(x = edad, y = MntWines))
g2<-ggplot(datos) + 
  geom_jitter(aes(x = edad, y = MntFruits))
g3<-ggplot(datos) + 
  geom_jitter(aes(x = edad, y = MntMeatProducts))
g4<-ggplot(datos) + 
  geom_jitter(aes(x = edad, y = MntFishProducts))
g5<-ggplot(datos) + 
  geom_jitter(aes(x = edad, y = MntSweetProducts))
g6<-ggplot(datos) + 
  geom_jitter(aes(x = edad, y = MntGoldProds))
g7<-ggplot(datos) + 
  geom_jitter(aes(x = edad, y = Dinero_Gastado))
gridExtra::grid.arrange(g1,g2,g3,g4, g5, g6, g7)
```
En una primera observación podemos ver que el gasto en vino es mucho mayor que en cualquiera de las otras secciones y para cualquier edad.
Por otra parte, no parece que existan patrones muy claros en ninguna de las variables. Sin embargo, podríamos decir que las personas de mayor edad gastan más dinero en vino y eso probablemente repercute en que gasten más dinero en general. 

Realizamos un último estudio en función del nivel de estudios y el estado sentimental. Pero primero vamos a ver cuantos datos hay de cada tipo.

```{r}
table(datos$Education, datos$Marital_Status)
```

```{r}
ggplot(datos) +
  geom_bar(aes(x = Education, fill = Marital_Status), position = "dodge")
```

Anteriormente hemos visto de forma general que el número de clientes con pareja son el doble de los sin pareja, pero ahora vemos esta relación se cumple además, para todos los grupos de niveles de estudio


Veamos la relación entre el salario y el nivel de estudios:

```{r}
ggplot(datos) +
  geom_boxplot(aes(x = factor(Education), y = Income))
```

Vemos que hay un outlier que no nos permite ver correctamente los gráficos. Por este motivo lo quitamos.

```{r}
aux <- datos %>%
  filter(Income < 500000)
ggplot(aux) +
  geom_boxplot(aes(x = factor(Education), y = Income))
```
Se puede observar cláramente que las personas con un nivel de estudio "Basic" ganan mucho menos que cualquiera de los otros 3 grupos. Otra cosa que hay que tener en cuenta es que entre los 3 grupos restantes no existen deiferencias significativas.



Por último vemos la relación entre el gasto y el nivel de estudios y la situación sentimental.

```{r}
g1 <- ggplot(datos) +
  geom_col(aes(x = Education, y = MntWines, fill = Marital_Status), position = "dodge")
g2<-ggplot(datos) + 
  geom_col(aes(x = Education, y = MntFruits, fill = Marital_Status), position = "dodge")
g3<-ggplot(datos) + 
  geom_col(aes(x = Education, y = MntMeatProducts, fill = Marital_Status), position = "dodge")
g4<-ggplot(datos) + 
  geom_col(aes(x = Education, y = MntFishProducts, fill = Marital_Status), position = "dodge")
g5<-ggplot(datos) + 
  geom_col(aes(x = Education, y = MntSweetProducts, fill = Marital_Status), position = "dodge")
g6<-ggplot(datos) + 
  geom_col(aes(x = Education, y = MntGoldProds, fill = Marital_Status), position = "dodge")
g7<-ggplot(datos) + 
  geom_col(aes(x = Education, y = Dinero_Gastado, fill = Marital_Status), position = "dodge")
gridExtra::grid.arrange(g1,g2,g3,g4, g5, g6, g7)
```

Estos gráficos reflejan lo visto anteriormente, ya que en todas las secciones, los clientes con un nivel de estudio "Basic" gastan mucho menos dinero que cualquiera de los otros 3 grupos, lo que concuerda con que su salario sea menor. 



## 3.2. Ajuste parámetros de control

Lo que haremos para para tener siempre un mismo resultado es usar una semilla, en nuestro caso será 2021. Por otro lado para el tema de control usaremos el método de cross-validation con un fold de 10.

```{r}
ctrl <- trainControl(method = "cv",number = 10,summaryFunction = defaultSummary,
                     classProbs = TRUE)
```

\newpage

## 3.3. Análisis sobre variable Complain

Otro análisis que se puede realizar mediante técnicas de machine learning es encontrar aquellas variables que son claves a la hora de detectar de forma anticipada que clientes se pueden quejar.
Para ello trabajaremos y realizaremos diferentes modelos de clasificación.

Lo primero antes de iniciar cualquier modelo, será ver como está distribuida la variable complain y también cambiarla para poder trabajar con ella:

```{r}
datos$Complain <- ifelse(datos$Complain == 1, 'Yes','No')
table(datos$Complain)
```


Tenemos que el dataset está totalmente desbalanceado, para evitar este problema lo que haremos será rebalancear nuestros datos. Esto nos puede generar alguna anomalía ya que estamos tratando los datos iniciales.

```{r}
set.seed(2021)
datos_comp_rebal <- ovun.sample(Complain ~ ., data = datos, method = 'both', 
                                N = table(datos$Complain)[1]*2)$data
table(datos_comp_rebal$Complain)
datos_comp_rebal <- datos_comp_rebal %>%
  select(-ID)
datos_comp_rebal$Complain <- as.factor(datos_comp_rebal$Complain)
```


Una vez que tenemos los datos rebalanceados podemos pasar al siguiente paso, que consistirá en mirar si tenemos variables que tengan una alta correlación: 


```{r, warning = FALSE, message = FALSE, fig.align='center', fig.dim=c(4,4)}
catvars <- sapply(datos_comp_rebal, class) %in% c("character","factpr")
numvars <- sapply(datos_comp_rebal, class) %in% c("integer","numeric")
C <- cor(datos_comp_rebal[,numvars])
corrplot(C, method = "circle")
```

Vemos que muchas variables tienen una alta correlación entre si, por ahora no haremos nada pero posteriormente veremos si es necesario eliminar alguna o no.

Una vez hecho esto podemos pasar a la parte de modelos, lo primero que haremos será dividir el conjunto de datos entre entrenamiento y test.

```{r}
set.seed(2021)
trainIndex2 <- createDataPartition(datos_comp_rebal$Complain, p = 0.8, list = FALSE, times = 1)
fTR2 <- datos_comp_rebal[trainIndex2,]
fTS2 <- datos_comp_rebal[-trainIndex2,] 
fTR2_eval <- fTR2
fTS2_eval <- fTS2
```

Una vez definido tanto el conjunto de entrenamiento como el de test realizaremos un modelo sencillo para ver cómo se comporta todo, este será una regresión logística. A su vez también usaremos como método de control un cross-validation con un fold de 10.

```{r, message=FALSE,warning=FALSE}
set.seed(2021)
LogReg.fit <- train(form = Complain ~ . , data = fTR2, method = "glm", 
                    trControl = ctrl, metric = "Accuracy")  
LogReg.fit  
```

Podemos observar que nuestro primer modelo, donde tenemos todas las variables, nos devuelve un accuracy de 0.695. Lo cual no esta mal para empezar, pero vayamos a lo que realmente nos interesa, que variables son importantes.

```{r}
summary(LogReg.fit)
```

Vemos que las variables importantes en nuestro modelo son el estado civil, la antigüedad del cliente, el consumo en diferentes productos, las veces que visitan la web, si respondes a la ofertas, la edad y el total de compras. Cabe destacar que este modelo solo detecta importancia de variables lineales con el output.



Evaluamos nuestro modelo para obtener datos más claros.

```{r, warning=FALSE, message=FALSE}
set.seed(2021)
fTR2_eval$LRprob <- predict(LogReg.fit, type="prob", newdata = fTR2)
fTR2_eval$LRpred <- predict(LogReg.fit, type="raw", newdata = fTR2)
fTS2_eval$LRprob <- predict(LogReg.fit, type="prob", newdata = fTS2) 
fTS2_eval$LRpred <- predict(LogReg.fit, type="raw", newdata = fTS2)
```


Ahora implementaremos otro modelo, que será el de arbol de decisiones. Este tiene la ventaja de que si nos dará las variables más importantes incluso si tienen relación no lineal con el output.

```{r, fig.dim=c(4,3), fig.align='center'}
set.seed(2021)
tree2.fit <- train(x = fTR2[,c(seq(1,11),seq(13,17))],y = fTR2$Complain,method ="rpart",
            control=rpart.control(minsplit=20,minbucket = 20), parms = list(split = "gini"),
            tuneGrid = data.frame(cp = seq(0,0.1,0.001)), trControl = ctrl,metric = "Accuracy")
ggplot(tree2.fit) 
```

Podemos observar que este modelo tiene un accuracy aproximado de 0.97 con un hiperparámetro c igual a 0. Elegimos $c = 0$ ya que es el valor que maximiza el accuracy.

A continuación veremos que variables son importantes, donde entrarán también en juego aquellas variables las cuales tengan relaciones no lineales con nuestro output.


```{r, fig.align='center'}
plot(varImp(tree2.fit,scale = FALSE))
```
Obtenemos que las variables más importantes son el consumo de productos "gourmet", carne y vino así como también la edad, los ingresos y el dinero gastado.


Por último haremos un modelo solo con las variables más importantes, tanto aquellas que tienen una relación lineal como aquellas que son no lineales. Para una mayor facilidad de comprensión del modelo y viendo como ha salido el último, realizaremos un arbol de decisión.

```{r,fig.dim=c(5,3.5), fig.align='center'}
set.seed(2021)
tree2_1.fit <- train(x = fTR2[,c(1,3,5,8,9,10,14,17)],y = fTR2$Complain,method ="rpart",
            control=rpart.control(minsplit=20,minbucket = 20), parms = list(split = "gini"),
            tuneGrid = data.frame(cp = seq(0,0.1,0.001)), trControl = ctrl,metric = "Accuracy")
ggplot(tree2_1.fit) 
```

En este caso vemos que el accuracy no varía y que se vuelve a coger el mismo valor de hiperparámetro.

Veamos como esta construido nuestro modelo de arbol de decisión:

```{r}
rpart.plot(tree2_1.fit$finalModel, type = 2, fallen.leaves = FALSE, box.palette = "Oranges")
```

Por último haremos como en el caso de la regresión logística, donde representamos graficamente la predicción frente a los valores reales de cada observación.

```{r}
set.seed(2021)
fTR2_eval$tree2_1_prob <- predict(tree2_1.fit, type="prob", newdata = fTR2) 
fTR2_eval$tree2_1_pred <- predict(tree2_1.fit, type="raw", newdata = fTR2)
fTS2_eval$tree2_1_prob <- predict(tree2_1.fit, type="prob", newdata = fTS2) 
fTS2_eval$tree2_1_pred <- predict(tree2_1.fit, type="raw", newdata = fTS2)
```


```{r}
Plot2DClass(fTR2[,c(1,3,5,8,9,10,14,17)],fTR2$Complain,tree2_1.fit,var1 = "edad", var2 = "Dinero_Gastado", selClass = "Yes")
```

A su vez, para ver que tal trabaja tanto en training como en test sacaremos ambas matrices de confusión:

```{r}
confusionMatrix(data = fTR2_eval$tree2_1_pred,reference = fTR2_eval$Complain,positive = "Yes")
```




```{r}
set.seed(2021)
confusionMatrix(data = fTS2_eval$tree2_1_pred,reference = fTS2_eval$Complain,positive = "Yes")
```


Por tanto, podemos afirmar que las variables que más importancia tienen para detectar que un cliente se va a quejar en un futuro son el gasto en productos "gourmet" y vino así como la edad, los ingresos y el dinero gastado. Esto se puede ver en la siguiente imagen:

```{r}
plot(varImp(tree2_1.fit,scale = FALSE))
```


